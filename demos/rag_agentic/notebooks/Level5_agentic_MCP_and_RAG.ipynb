{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
   "metadata": {},
   "source": [
    "# Level 5: MCP Based RAG (Medium Difficulty)\n",
    "\n",
    "This tutorial is for developers who are already familiar with [basic Agentic workflows](./Level2_simple_agentic_with_websearch.ipynb). This tutorial will highlight a couple of slightly more advanced use cases for agents where a single tool call is insufficient to complete the required task. Here we will rely on both agentic RAG and MCP server to expand our agents capabilities.\n",
    "\n",
    "We will also use MCP tools hosted locally or on an OpenShift cluster throughout this demo to showcase how users can go beyond Llama Stacks's current set of builtin tools to connect to many different services and data sources to build their own custom agents.\n",
    "\n",
    "Agent Examples:\n",
    "This notebook will walkthrough how to build a system that can answer each of the following 3 questions via agents built with Llama Stack:\n",
    "\n",
    "\"Check the status of my OpenShift cluster. If it’s running, create a new pod named test-pod in the dev namespace.\"\n",
    "\"Search for the latest Red Hat OpenShift version on the Red Hat website. Summarize the version number and draft a short email to my team.\"\n",
    "\"Review OpenShift logs for pods node-123 and node-456. Categorize each as ‘Normal’ or ‘Error’. If any show ‘Error’, send a Slack message to the ops team. Otherwise, show a simple summary.\"\n",
    "\n",
    "### Agent Examples:\n",
    "\n",
    "This notebook will walkthrough how to build a system that can answer each of the following question via agents built with Llama Stack:\n",
    "\n",
    "1. [*\"Generate a random number, insert it into: \"How much is an OpenShift subscription {number}?\", then query the vector DB with that question and return the results.\"*](#deploy-a-new-pod-in-our-openshift-cluster-with-mcp-enabled-agent)\n",
    "\n",
    "### MCP Tools:\n",
    "\n",
    "Throughout this notebook we will be relying on the [custom-mcp-server](hhttps://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/custom-mcp) to interact with our custom MCP tools.\n",
    "\n",
    "Please see installation instructions below if you do not already have this deployed in your environment. \n",
    "\n",
    "* [Custom MCP installation instructions](../../../mcp-servers/custom-mcp/README.md)\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will be connecting to a llama-stack instance, building a RAG agent with a custom MCP tool available to it, and inferencing against the agent.\n",
    "\n",
    "## Pre-Requisites\n",
    "\n",
    "Before starting, ensure you have the following:\n",
    "- User variables configured (see section `Setting your ENV variables` below).\n",
    "\n",
    "## General Setup\n",
    "\n",
    "\n",
    "### Setting your ENV variables:\n",
    "\n",
    "As mentioned above, for this demo there are a few ENV variables that need to set:\n",
    "- `REMOTE` (boolean): dictates if you are using a remote llama-stack instance.\n",
    "- `REMOTE_BASE_URL` (string): the URL for your llama-stack instance if using remote connection.\n",
    "- `REMOTE_CUSTOM_MCP_URL` (string): the URL for your CUSTOM MCP server. If the client does not find the tool registered to the llama-stack instance, it will use this URL to register the custom tool.\n",
    "\n",
    "### Installing dependencies\n",
    "\n",
    "This code requires `llama-stack` and the `llama-stack-client`, both at version `0.1.9`. Lets begin by installing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4481ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-stack-client==0.1.9 in ./venv/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: llama-stack==0.1.9 in ./venv/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (4.9.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (8.1.8)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (0.28.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (2.2.3)\n",
      "Requirement already satisfied: prompt-toolkit in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (3.0.50)\n",
      "Requirement already satisfied: pyaml in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (25.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (2.11.3)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (14.0.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (1.3.1)\n",
      "Requirement already satisfied: termcolor in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (3.0.1)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./venv/lib/python3.10/site-packages (from llama-stack-client==0.1.9) (4.13.2)\n",
      "Requirement already satisfied: blobfile in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (3.0.0)\n",
      "Requirement already satisfied: fire in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (0.7.0)\n",
      "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (0.30.2)\n",
      "Requirement already satisfied: jinja2>=3.1.6 in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (1.1.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (75.6.0)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (0.9.0)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.10/site-packages (from llama-stack==0.1.9) (11.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->llama-stack-client==0.1.9) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->llama-stack-client==0.1.9) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->llama-stack-client==0.1.9) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->llama-stack-client==0.1.9) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama-stack-client==0.1.9) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2>=3.1.6->llama-stack==0.1.9) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->llama-stack-client==0.1.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->llama-stack-client==0.1.9) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->llama-stack-client==0.1.9) (0.4.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in ./venv/lib/python3.10/site-packages (from blobfile->llama-stack==0.1.9) (3.22.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in ./venv/lib/python3.10/site-packages (from blobfile->llama-stack==0.1.9) (2.4.0)\n",
      "Requirement already satisfied: lxml>=4.9 in ./venv/lib/python3.10/site-packages (from blobfile->llama-stack==0.1.9) (5.3.2)\n",
      "Requirement already satisfied: filelock>=3.0 in ./venv/lib/python3.10/site-packages (from blobfile->llama-stack==0.1.9) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub->llama-stack==0.1.9) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.10/site-packages (from huggingface-hub->llama-stack==0.1.9) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub->llama-stack==0.1.9) (6.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.10/site-packages (from jsonschema->llama-stack==0.1.9) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.10/site-packages (from jsonschema->llama-stack==0.1.9) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.10/site-packages (from jsonschema->llama-stack==0.1.9) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.10/site-packages (from jsonschema->llama-stack==0.1.9) (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas->llama-stack-client==0.1.9) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->llama-stack-client==0.1.9) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->llama-stack-client==0.1.9) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->llama-stack-client==0.1.9) (2025.2)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.10/site-packages (from prompt-toolkit->llama-stack-client==0.1.9) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->llama-stack==0.1.9) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich->llama-stack-client==0.1.9) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich->llama-stack-client==0.1.9) (2.19.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.10/site-packages (from tiktoken->llama-stack==0.1.9) (2024.11.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->llama-stack-client==0.1.9) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client==0.1.9) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-stack-client==0.1.9 llama-stack==0.1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee3cb2",
   "metadata": {},
   "source": [
    "### Configuring logging\n",
    "\n",
    "Now that we have our dependencies, lets setup logging for the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25fc0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "if not logger.hasHandlers():  \n",
    "    logger.setLevel(logging.INFO)\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab2380",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "This section sets up key parameters for model inference and the RAG (Retrieval-Augmented Generation) vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbada131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Inference settings\n",
    "MODEL=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "TEMPERATURE = 0.0\n",
    "TOP_P = 0.95\n",
    "if TEMPERATURE > 0.0:\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": TEMPERATURE, \"top_p\": TOP_P}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "# RAG vector DB settings\n",
    "VECTOR_DB_EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "VECTOR_DB_EMBEDDING_DIMENSION = 384\n",
    "VECTOR_DB_CHUNK_SIZE = 512\n",
    "VECTOR_DB_PROVIDER_ID = \"faiss\"\n",
    "\n",
    "# Unique DB ID for session\n",
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681412e1",
   "metadata": {},
   "source": [
    "### Connecting to llama-stack server\n",
    "\n",
    "For the llama-stack instance, you can either run it locally or connect to a remote llama-stack instance.\n",
    "\n",
    "#### Remote llama-stack\n",
    "\n",
    "- For remote, be sure to set `remote` to `True` and populate the `remote_llama_stack_endpoint` variable with your llama-stack remote.\n",
    "- [Remote Setup Guide](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes)\n",
    "\n",
    "#### Local llama-stack\n",
    "- For local, be sure to set `remote` to `False` and validate the `local_llama_stack_endpoint` variable. It is based off of the default llama-stack port which is `8321` but is configurable with your deployment of llama-stack.\n",
    "- [Local Setup Guide](https://github.com/redhat-et/agent-frameworks/tree/main/prototype/frameworks/llamastack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fa38ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server @ http://localhost:8321 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "remote = os.getenv(\"REMOTE\", False) # Use the `remote` variable to switching between a local development environment and a remote kubernetes cluster.\n",
    "\n",
    "if remote:\n",
    "    base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "else:\n",
    "    base_url = \"http://localhost:8321\"\n",
    "\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\") # Replace with your Tavily API key (required for demo 2)\n",
    "\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data={\n",
    "        \"tavily_search_api_key\": tavily_search_api_key # This is required for demo 2\n",
    "    }\n",
    ")\n",
    "    \n",
    "logger.info(f\"Connected to Llama Stack server @ {base_url} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85664f8",
   "metadata": {},
   "source": [
    "### Indexing the Documents\n",
    "- Initialize a new document collection in the target vector DB. All parameters related to the vector DB, such as the embedding model and dimension, must be specified here.\n",
    "- Provide a list of document URLs to the RAG tool. Llama Stack will handle fetching, conversion and chunking of the documents' content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a8f4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import RAGDocument\n",
    "\n",
    "# define and register the document collection to be used\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=VECTOR_DB_EMBEDDING_MODEL,\n",
    "    embedding_dimension=VECTOR_DB_EMBEDDING_DIMENSION,\n",
    "    provider_id=VECTOR_DB_PROVIDER_ID,\n",
    ")\n",
    "\n",
    "# ingest the documents into the newly created document collection\n",
    "urls = [\n",
    "    (\"https://www.openshift.guide/openshift-guide-screen.pdf\", \"application/pdf\"),\n",
    "    (\"https://www.cdflaborlaw.com/_images/content/2023_OCBJ_GC_Awards_Article.pdf\", \"application/pdf\"),\n",
    "]\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=url_type,\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, (url, url_type) in enumerate(urls)\n",
    "]\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=VECTOR_DB_CHUNK_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66044170",
   "metadata": {},
   "source": [
    "### Validate tools are available in our llama-stack instance\n",
    "\n",
    "When an instance of llama-stack is redeployed your tools need to re-registered. Also if a tool is already registered with a llama-stack instance, if you try to register one with the same `toolgroup_id`, llama-stack will throw you an error.\n",
    "\n",
    "For this reason it is recommended to include some code to validate your tools and toolgroups. This is where the `mcp_url` comes into play. The following code will check that both the `builtin::rag` and the `mcp::custom_mcp_server` tools are registered as tools, but if the `mcp::custom_mcp_server` tool is not listed there, it will attempt to register it using the mcp url.\n",
    "\n",
    "If you are running the MCP server from source, the default value for this is: `http://localhost:8000/sse`.\n",
    "\n",
    "If you are running the MCP server from a container, the default value for this is: `http://host.containers.internal:8000/sse`.\n",
    "\n",
    "Make sure to pass the corresponding MCP URL for the server you are trying to register/validate tools for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your Llama Stack server is already registered with the following tool groups: {'builtin::rag', 'mcp::custom_mcp_server', 'builtin::websearch', 'builtin::wolfram_alpha'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Enter your MCP server URL here\n",
    "mcp_url = os.getenv(\"LOCAL_MCP_URL\") ######### REMOTE_CUSTOM_MCP_URL\n",
    "\n",
    "# Get list of registered tools and extract their toolgroup IDs\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [tool.toolgroup_id for tool in registered_tools]\n",
    "\n",
    "# # Unregister MCP tools\n",
    "# try:\n",
    "#     # Unregister MCP tools\n",
    "#     client.toolgroups.unregister(toolgroup_id=\"mcp::custom_mcp_server\")\n",
    "#     print(f\"Successfully unregistered MCP tool group: mcp:custom_tools\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error unregistering MCP tool group: {e}\")\n",
    "\n",
    "# Register MCP custom tool group if not already registered (Required for demo 2)\n",
    "if \"mcp::custom_mcp_server\" not in registered_toolgroups:\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::custom_mcp_server\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\": mcp_url},\n",
    "    )\n",
    "\n",
    "# Log the current toolgroups registered\n",
    "logger.info(\n",
    "    f\"Your Llama Stack server is already registered with the following tool groups: {set(registered_toolgroups)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5cbe2",
   "metadata": {},
   "source": [
    "## Query 1: (Agentic) `Using MCP Based RAG to Enhance Queries`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf70ace-b704-4379-aa88-3c793cc4f959",
   "metadata": {},
   "source": [
    "### System Prompts for different models\n",
    "\n",
    "**Note:** If you have multiple models configured with your Llama Stack server, you can choose which one to run your queries against. When switching to a different model, you may need to adjust the system prompt to align with that model’s expected behavior. Many models provide recommended system prompts for optimal and reliable outputs these are typically documented on their respective websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "374328a3-8c4d-4eb0-9c9d-73e40a9e74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a system prompt we have come up with which works well for this query\n",
    "\n",
    "granite_model=\"granite3.2:8b-instruct-fp16\"\n",
    "llama_model=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "sys_prompt1= \"\"\"You are a helpful assistant. Use tools to answer. When you use a tool always respond with a summary of the result.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b46bee8b-a46c-4b97-8273-dda75237d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[33m[\u001b[0m\u001b[33mgenerate\u001b[0m\u001b[33m_random\u001b[0m\u001b[33m_number\u001b[0m\u001b[33m(min\u001b[0m\u001b[33m=\u001b[0m\u001b[33m1\u001b[0m\u001b[33m,\u001b[0m\u001b[33m max\u001b[0m\u001b[33m=\u001b[0m\u001b[33m100\u001b[0m\u001b[33m),\u001b[0m\u001b[33m knowledge\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m(query\u001b[0m\u001b[33m=\"\u001b[0m\u001b[33mOpen\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m subscription\u001b[0m\u001b[33m {\u001b[0m\u001b[33mnumber\u001b[0m\u001b[33m}\")\u001b[0m\u001b[33m]\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:generate_random_number Args:{'min': 1.0, 'max': 100.0}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:generate_random_number Response:{\"type\":\"text\",\"text\":\"84\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m[k\u001b[0m\u001b[33mnowledge\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m(query\u001b[0m\u001b[33m=\"\u001b[0m\u001b[33mHow\u001b[0m\u001b[33m much\u001b[0m\u001b[33m is\u001b[0m\u001b[33m an\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m subscription\u001b[0m\u001b[33m \u001b[0m\u001b[33m84\u001b[0m\u001b[33m?\u001b[0m\u001b[33m\")]\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:knowledge_search Args:{'query': 'How much is an OpenShift subscription 84?'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:knowledge_search Response:[TextContentItem(text='knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n', type='text'), TextContentItem(text='Result 1:\\nDocument_id:num-0\\nContent: .\\nThese characteristics set OpenShift apart as an excellent Kubernetes platform for enterprise users.\\nThe latest version of OpenShift available at the time of this writing is 4.12.\\n3.2. Is Red Hat OpenShift Open Source?\\nRed Hat OpenShift is a commercial product based on an open-source project called OKD. This\\nacronym means \" OpenShift Kubernetes Distribution\" and is publicly available for everyone to\\ninspect and contribute. Like the upstream Kubernetes project, OKD developers use the Go\\nprogramming language.\\n3.3. How can I run OpenShift?\\nToday, Red Hat OpenShift is available through various mechanisms and formats:\\n• DevOps teams can install it in their data centers \"on-premise.\"\\n• Major hyperscalers such as AWS, Azure, Google Cloud Platform, and IBM Cloud offer managed\\nRed Hat OpenShift installations.\\n• Developers can either run OpenShift locally on their workstations using Red Hat OpenShift\\nLocal, also known as CRC or \"Code-Ready Containers\"\\n• They can also request a 30-day trial OpenShift cluster, offered by Red Hat, at no charge, for\\ntesting and evaluation purposes.\\nRed Hat OpenShift is an integrated Platform-as-a-Service for enterprise users based on Kubernetes.\\nIt is tightly integrated with advanced security settings, developer tooling, and monitoring\\nmechanisms, allowing DevOps teams to be more productive.\\n8\\nChapter 4. OpenShift-only Custom Resource\\nDefinitions\\nRed Hat OpenShift is a complete DevOps platform extending Kubernetes in various ways. It bundles\\na constellation of Custom Resource Definitions (CRDs) to make the life of developers and cluster\\nadministrators easier.\\nLet us talk first about the CRDs only available on OpenShift.\\n4.1. Project\\nAn OpenShift Project is similar to a Kubernetes namespace, but more tightly integrated into the\\nsecurity system of OpenShift through additional annotations.\\napiVersion: project.openshift.io/v1\\nkind: Project\\nmetadata:\\n\\xa0 name: linkedin-learning-project\\n\\xa0 annotations:\\n\\xa0   openshift.io/description: \"Project description\"\\n\\xa0   openshift.io/display-name: \"Display name\"\\n4.2. Route\\nThe OpenShift Route object was one of the primary inspirations during the development of the\\nIngress object. In OpenShift, Ingress and Route objects work together to ensure your applications\\nare available outside the cluster.\\napiVersion: route.openshift.io/v1\\nkind: Route\\nmetadata:\\n\\xa0 name: my-route\\nspec:\\n\\xa0 host:\\n', type='text'), TextContentItem(text='Result 2:\\nDocument_id:num-0\\nContent:  We\\nrecommend you to check the official Red Hat OpenShift Local documentation for an updated list of\\nrequirements at the official documentation website.\\n\\uf05a\\nRegarding Linux, even if Red Hat does not officially support them, OpenShift Local\\ncan run on other distributions, such as Ubuntu or Debian, with minor caveats.\\nRunning OpenShift Local on any Linux distribution requires a few additional\\nsoftware packages to be installed through your default package manager. The\\n15\\ndocumentation at crc.dev/crc has more information about this subject.\\n7.2. Hardware Requirements\\nIn terms of hardware, OpenShift Local has some strict requirements. Your system must use a recent\\nIntel CPU (except for Macs, where Apple Silicon machines are supported) with at least four physical\\ncores and have at least 16 GB of RAM. Be aware that the base installation of OpenShift Local\\nrequires at least 9 GB free to start. Of course, to run other applications on OpenShift Local, you will\\nneed more RAM, so using a computer with at least 32 GB of RAM is strongly recommended.\\nOpenShift Local also requires at least 35 GB of free disk space for its installation. The memory\\nrequirements are likely to increase in the future, so please check the documentation at crc.dev for\\nmore up-to-date information.\\n7.3. Installation\\nTo install OpenShift Local, open your web browser and navigate to console.redhat.com/openshift/\\ncreate/local . Download the latest release of OpenShift Local and the \"pull secret\" file. The latter is a\\nfile containing a key identifying your copy of OpenShift Local to your Red Hat Developer account.\\nUnzip the file containing the OpenShift Local executable, and using your terminal, run the\\ncommand crc setup . This command will prepare your copy of OpenShift Local, verifying\\nrequirements and setting the required configuration values.\\nOnce the crc setup command is ready, launch crc start. Running crc start can take a long time,\\naround 20 minutes, on a recent PC.\\nOnce started, access the OpenShift Web Console with the crc console command, which will open\\nyour default browser. OpenShift Local uses the developer username and password to log in as a\\nlow-privilege user, while the kubeadmin user uses a random-generated password. Use the crc\\nconsole --credentials command to find the credentials required to log in as the kubeadmin user.\\nOpenShift Local allows developers to perform various everyday tasks as if it were a standard\\nOpenShift cluster, like deploying applications\\n', type='text'), TextContentItem(text='Result 3:\\nDocument_id:num-0\\nContent:  the Developer Sandbox for Red Hat OpenShift, a free\\nservice by Red Hat with which developers can get access to a fully managed cluster for 30 days. The\\nDeveloper Sandbox for Red Hat OpenShift is an ideal solution for those interested in knowing more\\nabout OpenShift with the least effort.\\nWith the Developer Sandbox for Red Hat OpenShift, developers can deploy their applications in a\\nsecure and fully managed environment. Red Hat even provides guided activities, but developers\\ncan deploy their container images and use their deployment manifestos.\\nYou only need a free Red Hat developer account to use the Developer Sandbox for Red Hat\\nOpenShift. Your free Red Hat developer account will give you access to many resources and\\nsoftware, freely available at developers.redhat.com.\\nFigure 2. Red Hat Developer Sandbox home page\\n6.1. Demo\\nGo to developers.redhat.com/developer-sandbox and click on the [\\u2009Start your sandbox for free\\u2009] \\nbutton. Log into your account, and if this is the first time you have accessed the Developer Sandbox,\\nRed Hat will ask you to confirm your account. Confirmation is required to avoid service abuse. The\\neasiest way to verify your account is by entering a code sent via SMS. After entering the code, you’ll\\nreceive a confirmation email. Depending on the system’s load, this verification can take some time.\\nOnce confirmed, you can navigate with your browser to developers.redhat.com/developer-sandbox\\n13\\nand log in directly to your very own temporary OpenShift cluster! It’s that simple.\\n6.2. Dev Spaces\\nAn exciting feature of the Developer Sandbox for Red Hat OpenShift is Red Hat OpenShift Dev\\nSpaces, a fully integrated developer environment within Red Hat OpenShift, allowing developers to\\ncreate and deploy applications in various programming languages and frameworks from within the\\nOpenShift cluster.\\nRed Hat OpenShift Dev Spaces also includes the web version of Microsoft Visual Studio Code, the\\npopular text editor for developers. Visual Studio Code allows developers to work in a professional\\nenvironment, including Git support, deploying their applications in a few clicks on a ready-to-use\\nOpenShift cluster.\\nYou can create Red Hat OpenShift Dev Spaces workspaces in various technologies: Go, .NET, Java\\n(using the Quarkus framework), Node.js, Python, (©), C++, Rust, PHP, and Scala, among many others.\\nDev Spaces also integrates with the odo command line tool through an auto-generated Devfile,\\nspecifying all the dependencies and steps\\n', type='text'), TextContentItem(text='Result 4:\\nDocument_id:num-0\\nContent:  Git repository, for example, but not\\n22\\nlimited to GitHub, GitLab, Gitea, or other locations.\\n• Importing YAML directly or even a JAR file with a Java application.\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\ncontainer.\\nEnter the URL of the container on the field, and click on the [\\u2009Create\\u2009] button at the bottom of the\\npage. You do not need to change any other value on the form.\\nA few seconds later, depending on the size of the container and the speed of your Internet\\nconnection, OpenShift will have pulled the container and deployed it onto your cluster. This\\ndeployment will include the usual standard elements: a \"Deployment\" object, a \"Service\" object, and\\na \"Route.\"\\nOpenShift offers a visual representation of the applications running on your project: click on the\\nicon of your container, and you will see a panel opening on the right side of the screen. This panel\\nwill include the URL automatically assigned to your deployment, and clicking it will show the\\napplication in action in another browser tab.\\nFigure 4. Topology screen on Red Hat OpenShift\\n9.2. Creating and Debugging Applications with the odo\\nTool\\nWith the oc tool, Red Hat provides another one geared toward software developers: the odo tool.\\nDevelopers can use the odo tool to create applications using \"Devfiles,\" particular files named\\n\"devfile.yaml\" based on an open standard available at the Devfiles website. Devfiles contain\\ninformation about your application’s programming language, dependencies, and other essential\\ndetails.\\n23\\nThe odo tool is not available by default on your command line, but you can download it from the\\n\"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry. Click on the\\n\"Download odo\" link at the bottom, and select the version of odo that corresponds to your system.\\nThe \"odo catalog list components was\" command shows the various programming languages and\\nframeworks supported off-the-box by \"odo.\"\\nThe odo init  command prompts the user for a new application using many programming\\nlanguages: .NET, Go, Java, JavaScript, PHP, Python, and TypeScript. The last command generates a\\nscaffold ready to be populated with the required logic. Finally, the odo push command builds and\\npushes the container to the OpenShift container registry, deploying\\n', type='text'), TextContentItem(text='Result 5:\\nDocument_id:num-0\\nContent: 23\\ninstall OpenShift Local, 16\\nJ\\nJAR file, 23\\nJava, 14, 24, 44\\nJavaScript, 24, 44\\nJenkins, 28\\nK\\nKiali, 36\\nKibana, 40, 40\\nKnative, 34\\nKubernetes, 7\\nL\\nlogs, 40\\nM\\nMicroservices, 36\\nmonitor, 40\\nN\\nNode.js, 14\\nnon-root accounts, 20\\nO\\nOpenShift 4.12, 33\\nOpenShift Kubernetes Distribution, 8\\nOpenShift Service Mesh, 36\\noperator, 28, 36\\nOperatorHub, 33, 36\\nOperators, 33\\n48\\nP\\nperspectives, 22\\nPHP, 14, 24\\nPlatform-as-a-Service, 8\\nprivilege escalation, 19\\nprivileged ports, 20\\nProject, 9\\nPrometheus, 40, 44\\nPromQL, 45\\nPython, 14, 24, 44\\nQ\\nQuarkus, 14, 44\\nR\\nRed Hat developer account, 13\\nRed Hat OpenShift, 7\\nRed Hat OpenShift Dev Spaces, 14\\nRed Hat OpenShift Local, 8, 15\\nRed Hat OpenShift Pipelines, 28\\nRed Hat Quay, 20\\nRed Hat Universal Base Images, 19\\nrole, 19\\nRoute, 9\\nRust, 14\\nS\\nScala, 14\\nScaling, 42\\nsecure by default, 19\\nSecurity Context Constraints, 19\\nServerless, 34\\nservice mesh, 36\\nsource code project, 22\\nstateful applications, 33\\nT\\nTekton, 28\\ntemplates, 32\\nTopology, 27\\nTwelve-Factor App, 21, 40\\nTypeScript, 24\\nU\\nUBI, 19\\nV\\nVertical scaling, 42\\nVisual Studio Code, 14\\nW\\nWeb Console, 22, 40\\n49\\n', type='text'), TextContentItem(text='END of knowledge_search tool results.\\n', type='text')]\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33mBased\u001b[0m\u001b[33m on\u001b[0m\u001b[33m the\u001b[0m\u001b[33m provided\u001b[0m\u001b[33m text\u001b[0m\u001b[33m,\u001b[0m\u001b[33m here\u001b[0m\u001b[33m is\u001b[0m\u001b[33m a\u001b[0m\u001b[33m summary\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m key\u001b[0m\u001b[33m points\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m**\u001b[0m\u001b[33mRed\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m**\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m is\u001b[0m\u001b[33m a\u001b[0m\u001b[33m container\u001b[0m\u001b[33m application\u001b[0m\u001b[33m platform\u001b[0m\u001b[33m that\u001b[0m\u001b[33m provides\u001b[0m\u001b[33m a\u001b[0m\u001b[33m managed\u001b[0m\u001b[33m platform\u001b[0m\u001b[33m for\u001b[0m\u001b[33m building\u001b[0m\u001b[33m,\u001b[0m\u001b[33m deploying\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m managing\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m It\u001b[0m\u001b[33m offers\u001b[0m\u001b[33m a\u001b[0m\u001b[33m web\u001b[0m\u001b[33m-based\u001b[0m\u001b[33m console\u001b[0m\u001b[33m for\u001b[0m\u001b[33m managing\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m,\u001b[0m\u001b[33m as\u001b[0m\u001b[33m well\u001b[0m\u001b[33m as\u001b[0m\u001b[33m command\u001b[0m\u001b[33m-line\u001b[0m\u001b[33m tools\u001b[0m\u001b[33m such\u001b[0m\u001b[33m as\u001b[0m\u001b[33m `\u001b[0m\u001b[33moc\u001b[0m\u001b[33m`\u001b[0m\u001b[33m and\u001b[0m\u001b[33m `\u001b[0m\u001b[33modo\u001b[0m\u001b[33m`.\n",
      "\n",
      "\u001b[0m\u001b[33m**\u001b[0m\u001b[33mKey\u001b[0m\u001b[33m Features\u001b[0m\u001b[33m**\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Supports\u001b[0m\u001b[33m multiple\u001b[0m\u001b[33m programming\u001b[0m\u001b[33m languages\u001b[0m\u001b[33m,\u001b[0m\u001b[33m including\u001b[0m\u001b[33m .\u001b[0m\u001b[33mNET\u001b[0m\u001b[33m,\u001b[0m\u001b[33m Go\u001b[0m\u001b[33m,\u001b[0m\u001b[33m Java\u001b[0m\u001b[33m,\u001b[0m\u001b[33m JavaScript\u001b[0m\u001b[33m,\u001b[0m\u001b[33m PHP\u001b[0m\u001b[33m,\u001b[0m\u001b[33m Python\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m TypeScript\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Offers\u001b[0m\u001b[33m Dev\u001b[0m\u001b[33mfiles\u001b[0m\u001b[33m,\u001b[0m\u001b[33m which\u001b[0m\u001b[33m are\u001b[0m\u001b[33m files\u001b[0m\u001b[33m that\u001b[0m\u001b[33m contain\u001b[0m\u001b[33m information\u001b[0m\u001b[33m about\u001b[0m\u001b[33m an\u001b[0m\u001b[33m application\u001b[0m\u001b[33m's\u001b[0m\u001b[33m programming\u001b[0m\u001b[33m language\u001b[0m\u001b[33m,\u001b[0m\u001b[33m dependencies\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m other\u001b[0m\u001b[33m essential\u001b[0m\u001b[33m details\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Provides\u001b[0m\u001b[33m a\u001b[0m\u001b[33m visual\u001b[0m\u001b[33m representation\u001b[0m\u001b[33m of\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m running\u001b[0m\u001b[33m on\u001b[0m\u001b[33m the\u001b[0m\u001b[33m platform\u001b[0m\u001b[33m,\u001b[0m\u001b[33m with\u001b[0m\u001b[33m a\u001b[0m\u001b[33m topology\u001b[0m\u001b[33m screen\u001b[0m\u001b[33m that\u001b[0m\u001b[33m shows\u001b[0m\u001b[33m the\u001b[0m\u001b[33m URL\u001b[0m\u001b[33m of\u001b[0m\u001b[33m each\u001b[0m\u001b[33m deployment\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Supports\u001b[0m\u001b[33m state\u001b[0m\u001b[33mful\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m and\u001b[0m\u001b[33m provides\u001b[0m\u001b[33m features\u001b[0m\u001b[33m such\u001b[0m\u001b[33m as\u001b[0m\u001b[33m scaling\u001b[0m\u001b[33m,\u001b[0m\u001b[33m security\u001b[0m\u001b[33m context\u001b[0m\u001b[33m constraints\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m secure\u001b[0m\u001b[33m by\u001b[0m\u001b[33m default\u001b[0m\u001b[33m.\n",
      "\n",
      "\u001b[0m\u001b[33m**\u001b[0m\u001b[33mTools\u001b[0m\u001b[33m**\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m `\u001b[0m\u001b[33moc\u001b[0m\u001b[33m`\u001b[0m\u001b[33m (\u001b[0m\u001b[33mOpen\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m Client\u001b[0m\u001b[33m)\u001b[0m\u001b[33m is\u001b[0m\u001b[33m a\u001b[0m\u001b[33m command\u001b[0m\u001b[33m-line\u001b[0m\u001b[33m tool\u001b[0m\u001b[33m for\u001b[0m\u001b[33m managing\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m resources\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m `\u001b[0m\u001b[33modo\u001b[0m\u001b[33m`\u001b[0m\u001b[33m (\u001b[0m\u001b[33mOpen\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m Developer\u001b[0m\u001b[33m Tool\u001b[0m\u001b[33m)\u001b[0m\u001b[33m is\u001b[0m\u001b[33m a\u001b[0m\u001b[33m tool\u001b[0m\u001b[33m for\u001b[0m\u001b[33m creating\u001b[0m\u001b[33m and\u001b[0m\u001b[33m debugging\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m using\u001b[0m\u001b[33m Dev\u001b[0m\u001b[33mfiles\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m `\u001b[0m\u001b[33mK\u001b[0m\u001b[33miali\u001b[0m\u001b[33m`,\u001b[0m\u001b[33m `\u001b[0m\u001b[33mK\u001b[0m\u001b[33mib\u001b[0m\u001b[33mana\u001b[0m\u001b[33m`,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m `\u001b[0m\u001b[33mProm\u001b[0m\u001b[33metheus\u001b[0m\u001b[33m`\u001b[0m\u001b[33m are\u001b[0m\u001b[33m monitoring\u001b[0m\u001b[33m tools\u001b[0m\u001b[33m that\u001b[0m\u001b[33m provide\u001b[0m\u001b[33m insights\u001b[0m\u001b[33m into\u001b[0m\u001b[33m the\u001b[0m\u001b[33m platform\u001b[0m\u001b[33m's\u001b[0m\u001b[33m performance\u001b[0m\u001b[33m and\u001b[0m\u001b[33m security\u001b[0m\u001b[33m.\n",
      "\n",
      "\u001b[0m\u001b[33m**\u001b[0m\u001b[33mSecurity\u001b[0m\u001b[33m**\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m provides\u001b[0m\u001b[33m secure\u001b[0m\u001b[33m by\u001b[0m\u001b[33m default\u001b[0m\u001b[33m features\u001b[0m\u001b[33m,\u001b[0m\u001b[33m including\u001b[0m\u001b[33m security\u001b[0m\u001b[33m context\u001b[0m\u001b[33m constraints\u001b[0m\u001b[33m and\u001b[0m\u001b[33m privileged\u001b[0m\u001b[33m ports\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Supports\u001b[0m\u001b[33m non\u001b[0m\u001b[33m-root\u001b[0m\u001b[33m accounts\u001b[0m\u001b[33m and\u001b[0m\u001b[33m role\u001b[0m\u001b[33m-based\u001b[0m\u001b[33m access\u001b[0m\u001b[33m control\u001b[0m\u001b[33m.\n",
      "\n",
      "\u001b[0m\u001b[33m**\u001b[0m\u001b[33mOther\u001b[0m\u001b[33m Features\u001b[0m\u001b[33m**\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Supports\u001b[0m\u001b[33m multiple\u001b[0m\u001b[33m container\u001b[0m\u001b[33m run\u001b[0m\u001b[33mtimes\u001b[0m\u001b[33m,\u001b[0m\u001b[33m including\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Universal\u001b[0m\u001b[33m Base\u001b[0m\u001b[33m Images\u001b[0m\u001b[33m (\u001b[0m\u001b[33mUB\u001b[0m\u001b[33mI\u001b[0m\u001b[33m).\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Offers\u001b[0m\u001b[33m a\u001b[0m\u001b[33m Platform\u001b[0m\u001b[33m-as\u001b[0m\u001b[33m-a\u001b[0m\u001b[33m-\u001b[0m\u001b[33mService\u001b[0m\u001b[33m (\u001b[0m\u001b[33mP\u001b[0m\u001b[33maaS\u001b[0m\u001b[33m)\u001b[0m\u001b[33m model\u001b[0m\u001b[33m for\u001b[0m\u001b[33m building\u001b[0m\u001b[33m and\u001b[0m\u001b[33m deploying\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m.\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Integr\u001b[0m\u001b[33mates\u001b[0m\u001b[33m with\u001b[0m\u001b[33m other\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m products\u001b[0m\u001b[33m,\u001b[0m\u001b[33m such\u001b[0m\u001b[33m as\u001b[0m\u001b[33m Jenkins\u001b[0m\u001b[33m,\u001b[0m\u001b[33m Tek\u001b[0m\u001b[33mton\u001b[0m\u001b[33m,\u001b[0m\u001b[33m and\u001b[0m\u001b[33m Operator\u001b[0m\u001b[33mHub\u001b[0m\u001b[33m.\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import Agent\n",
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=MODEL, # replace this with your choice of model\n",
    "    instructions = sys_prompt1 , # update system prompt based on the model you are using\n",
    "    tools=[\n",
    "        dict(\n",
    "            name=\"builtin::rag/knowledge_search\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        ),\n",
    "\n",
    "        \"mcp::custom_mcp_server\"\n",
    "\n",
    "           \n",
    "           ],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params={\"max_tokens\":4096}\n",
    ")\n",
    "\n",
    "user_prompts = [\"\"\"\n",
    "Generate a random number, insert it into: \"How much is an OpenShift subscription {number}?\", then query the vector DB with that question and return the results.\n",
    "\"\"\"]\n",
    "\n",
    "\n",
    "                \n",
    "session_id = agent.create_session(session_name=\"OCP_demo\")\n",
    "\n",
    "for prompt in user_prompts:\n",
    "    turn_response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=True,\n",
    "    )\n",
    "    for log in EventLogger().log(turn_response):\n",
    "        log.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
