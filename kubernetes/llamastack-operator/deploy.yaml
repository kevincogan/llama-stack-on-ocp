apiVersion: llama.x-k8s.io/v1alpha1
kind: LlamaStackaDistribution
metadata:
  name: llamastackdistribution-sample
  namespace: <user-defined-namespace>
spec:
  replicas: 1
  server:
    containerSpec:
      image: "llamastack/distribution-ollama:latest"
      port: 8321
      env:
      - name: INFERENCE_MODEL
        value: "meta-llama/Llama-3.2-3B-Instruct"
      - name: OLLAMA_URL
        value: "http://ollama-server-service.default.svc.cluster.local:11434"
    podOverrides:
      volumes:
      - name: llama-storage
        emptyDir: {}
      volumeMounts:
      - name: llama-storage
        mountPath: "/root/.llama"